import json
import pandas as pd
import torch
from datasets import Dataset
from modelscope import snapshot_download, AutoTokenizer
from swanlab.integration.huggingface import SwanLabCallback
from peft import LoraConfig, TaskType, get_peft_model
from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq
import os
import swanlab
from datasets import load_dataset
from trl import DPOTrainer, DPOConfig
from transformers import DataCollatorWithPadding
from tqdm import tqdm

def print_trainable_parameters(model):
    total_params = 0
    total_trainable_params = 0
    for name, param in model.named_parameters():
        param_count = param.numel()  # è®¡ç®—å‚æ•°æ•°é‡
        total_params += param_count
        if param.requires_grad:
            total_trainable_params += param_count
            print(f"{name}: {param_count} trainable")
    print(f"Total parameters: {total_params}")
    print(f"Trainable parameters: {total_trainable_params}")
    return total_trainable_params
    
# åœ¨modelscopeä¸Šä¸‹è½½Qwenæ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ä¸‹
model_dir = snapshot_download("qwen/Qwen2.5-1.5B-Instruct", cache_dir="./", revision="master")

# TransformersåŠ è½½æ¨¡å‹æƒé‡
tokenizer = AutoTokenizer.from_pretrained("./qwen/Qwen2___5-1___5B-Instruct/", use_fast=False, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained("./qwen/Qwen2___5-1___5B-Instruct/", device_map="auto", torch_dtype=torch.bfloat16)
model.enable_input_require_grads()  # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶ï¼Œè¦æ‰§è¡Œè¯¥æ–¹æ³•

if tokenizer.bos_token is None:   # qwenæ²¡æœ‰bos_tokenï¼Œè¦è®¾ç½®ä¸€ä¸‹ï¼Œä¸ç„¶dpo trainæ—¶ä¼šæŠ¥é”™ã€‚
    tokenizer.add_special_tokens({"bos_token": tokenizer.eos_token})
    tokenizer.bos_token_id = tokenizer.eos_token_id
tokenizer.padding_side = "right"

# åŠ è½½ã€å¤„ç†æ•°æ®é›†å’Œæµ‹è¯•é›†
TRAIN_FILE = "./train.jsonl"
VAL_FILE = "./val.jsonl"
print("æ­£åœ¨åŠ è½½å¹¶å¤„ç†æ•°æ®é›†...")

import random
from datasets import Dataset

# -------------------------
# 1. è¯»å–å…¨ç±»åˆ«
# -------------------------
def get_all_classes(path):
    classes = set()
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            item = json.loads(line)
            for msg in item["messages"]:
                if msg["role"] == "assistant":
                    classes.add(msg["content"].strip())
                    break
    return sorted(list(classes))


# -------------------------
# 2. æå– prompt / label
# -------------------------
def extract_label(item):
    for msg in item["messages"]:
        if msg["role"] == "assistant":
            return msg["content"].strip()
    return None

def extract_prompt(item):
    for msg in item["messages"]:
        if msg["role"] == "user":
            return msg["content"].strip()
    return ""


# -------------------------
# 3. æ„å»º DPO æ•°æ®
# -------------------------

def build_dpo_data(input_file, all_classes):
    dpo_list = []
    with open(input_file, "r", encoding="utf-8") as f:
        for line in f:
            item = json.loads(line)

            label = extract_label(item)
            prompt = extract_prompt(item)

            negatives = [c for c in all_classes if c != label]
            neg_samples = random.sample(negatives, 3)

            for neg in neg_samples:
                dpo_list.append({
                    "prompt": prompt,
                    "chosen": label,
                    "rejected": neg
                })

    return dpo_list

# -------------------------
# 4. ä¸»æµç¨‹
# -------------------------

all_classes = get_all_classes(TRAIN_FILE)
print("ç±»åˆ«æ•°ï¼š", len(all_classes))
dpo_list = build_dpo_data(TRAIN_FILE, all_classes)
dpo_dataset = Dataset.from_list(dpo_list)


config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    inference_mode=False,  # è®­ç»ƒæ¨¡å¼
    r=8,  # Lora ç§©
    lora_alpha=32,  # Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†
    lora_dropout=0.1,  # Dropout æ¯”ä¾‹
)

model = get_peft_model(model, config)
print_trainable_parameters(model)  

training_args = DPOConfig(
    output_dir="./dpo_output",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=1e-4,
    num_train_epochs=3,
    logging_steps=10,
    save_steps=500,
    save_total_limit=3,
    bf16=True,

    # â­ DPO æ ¸å¿ƒå‚æ•°
    beta=0.1,
    max_length=512,
    max_prompt_length=256,
    #max_target_length=256,

    report_to=["swanlab"],
    remove_unused_columns=False,
)


swanlab_callback = SwanLabCallback(
    project="Qwen2.5-fintune",
    experiment_name="Qwen2.5-1.5B-dpo-fintune",
    description="ä½¿ç”¨é€šä¹‰åƒé—®Qwen2-1.5B-Instructæ¨¡å‹åœ¨æ•°æ®é›†ä¸Šå¾®è°ƒã€‚",
    config={
        "model": "qwen/Qwen2.5-1.5B-Instruct",
        "dataset": "./train.jsonl",
    }
)

# åˆ›å»º DPOTrainer æ—¶ï¼Œç›´æ¥ä½¿ç”¨ processing_class
trainer = DPOTrainer(
    model=model,
    ref_model=None,          # LoRA åœºæ™¯å¿…é¡» None
    args=training_args,
    train_dataset=dpo_dataset,
    callbacks=[swanlab_callback],
)

trainer.train()


VAL_FILE = "./val.jsonl"
RESULT_FILE = ".dpo_result.jsonl"
MAX_NEW_TOKENS = 12 
model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

print(f"æ­£åœ¨è¯»å–éªŒè¯é›†: {VAL_FILE}")
data_samples = []
with open(VAL_FILE, "r", encoding="utf-8") as f:
    for line in f:
        if line.strip():
            data_samples.append(json.loads(line))

print(f"å…±åŠ è½½ {len(data_samples)} æ¡éªŒè¯æ•°æ®ã€‚")
def predict(messages, model, tokenizer):
    """
    ç”Ÿæˆå›å¤å¹¶åªè¿”å›ç”Ÿæˆçš„æ–‡æœ¬éƒ¨åˆ†
    """
    # æ„é€  Prompt
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    inputs = tokenizer([text], return_tensors="pt").to(model.device)
   
    with torch.no_grad():
        generated_ids = model.generate(
            inputs.input_ids,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=False,
            temperature=0.1,  # éªŒè¯æ—¶æ¸©åº¦è®¾ä½ä¸€ç‚¹ï¼Œä¿è¯ç»“æœç¡®å®šæ€§
            top_p=0.9
        )

    # è£å‰ªæ‰ Input éƒ¨åˆ†ï¼Œåªå– Output
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)
    ]
 
    
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response

def check_correctness(response, ground_truth):
    """
    åˆ¤åˆ«é€»è¾‘ï¼šåªè¦ç”Ÿæˆçš„å›ç­”åŒ…å«å®Œæ•´çš„ ground truthï¼Œå³ä¸ºæ­£ç¡®
    """
    # ç®€å•çš„å­—ç¬¦ä¸²åŒ…å«åˆ¤æ–­
    return ground_truth in response


base_correct_count = 0
ft_correct_count = 0
total_count = 0
results_log = []

print("\nğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–è¯„ä¼°...")
pbar = tqdm(data_samples, desc="Evaluating", unit="sample")

for sample in pbar:
    total_count += 1
    
    # æå–è¾“å…¥å’Œæ ‡å‡†ç­”æ¡ˆ
    input_messages = sample["messages"][:-1]
    ground_truth = sample["messages"][-1]["content"]
    ft_response = predict(input_messages, model, tokenizer)
    is_ft_correct = check_correctness(ft_response, ground_truth)
    if is_ft_correct:
        ft_correct_count += 1

    results_log.append({
        "input": input_messages[-1]["content"], 
        "ground_truth": ground_truth,
        "ft_response": ft_response,
        "ft_correct": is_ft_correct
    })

    current_ft_acc = ft_correct_count / total_count
    pbar.set_postfix({ 
        "FT_Acc": f"{current_ft_acc:.2%}"
    })

final_ft_acc = ft_correct_count / total_count

print("\n" + "="*50)
print("æœ€ç»ˆè¯„ä¼°æŠ¥å‘Š")
print("="*50)
print(f"éªŒè¯é›†æ€»æ•°: {total_count}")
print("åˆ¤åˆ«æ ‡å‡†: ç”Ÿæˆå†…å®¹å¿…é¡»åŒ…å« Ground Truth")
print("-" * 30)
print(f"å¾®è°ƒæ¨¡å‹ æ­£ç¡®æ•°: {ft_correct_count}")
print(f"å¾®è°ƒæ¨¡å‹ å‡†ç¡®ç‡: {final_ft_acc:.2%}")
print("="*50)

# ä¿å­˜è¯¦ç»†ç»“æœ
with open(RESULT_FILE, "w", encoding="utf-8") as f:
    json.dump(results_log, f, ensure_ascii=False, indent=2)
print(f"è¯¦ç»†å¯¹æ¯”æ—¥å¿—å·²ä¿å­˜è‡³: {RESULT_FILE}")

swanlab.finish()
